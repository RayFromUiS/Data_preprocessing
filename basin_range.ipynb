{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import unicodedata as ud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_coor_basin(basin_file):\n",
    "    ''' split coordinate for each basin row data\n",
    "    '''\n",
    "    basin = pd.read_excel(basin_file)\n",
    "    basin.set_index('Unnamed: 0',inplace=True)\n",
    "    basin_row_con = {} ## data container\n",
    "#     basin_row_2d = [] ## basin row container\n",
    "    #iterate rows\n",
    "    for i in range(1,len(basin)):\n",
    "        basin_row_list = [] # row data container\n",
    "        basin_row = basin.iloc[i]\n",
    "        for j in range(len(basin_row)):\n",
    "            basin_row_pari = []\n",
    "            if ',' in str(basin_row[j]) and basin_row[j]:\n",
    "                basin_row_col_split = str(basin_row[j]).split(',') #split data\n",
    "                if re.match(r'-*\\d',basin_row_col_split[0]) and re.match(r'-*\\d',basin_row_col_split[1]): ##data is not null and valid\n",
    "                    basin_row_pari.append(basin_row_col_split[0]) #saving long\n",
    "                    basin_row_pari.append(basin_row_col_split[1]) #saving lat\n",
    "            basin_row_list.append(basin_row_pari) #saving pair to basin_row\n",
    "        basin_row_con[basin_row.name] = basin_row_list ## append list to 2d row container\n",
    "#         basin_row_con[basin_row.name] = basin_row_2d\n",
    "    return basin_row_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_basin_data = split_coor_basin('basin.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_test_df = pd.DataFrame.from_dict(split_basin_data['Faroe - Shetland Escarpment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_field_df(split_basin_data):\n",
    "    '''generate dataframe for each field with such column,basin,lat,and long\n",
    "    \n",
    "    '''\n",
    "    basin_tuple = {}\n",
    "    basin_dfs = []\n",
    "    for key in split_basin_data.keys(): ##iterate through the libaries\n",
    "        basin_df = pd.DataFrame.from_dict(split_basin_data[key]) ## gen dataframe\n",
    "        basin_df = basin_df[~basin_df.isnull()]\n",
    "        basin_df.dropna(inplace=True)\n",
    "        basin_df['basin'] = key\n",
    "        basin_dfs.append(basin_df) ## append dataframe to list\n",
    "        \n",
    "    \n",
    "    basin_df_con = pd.concat(basin_dfs) ##concata together\n",
    "#     basin_df_con = basin_df_con[~basin_df_con.isnull()] ##find null value\n",
    "#     basin_df_con.dropna(inplace=True)\n",
    "    basin_df_con.columns = ['long','lat','basin']\n",
    "    basin_df_con['long'] = basin_df_con['long'].map(float)\n",
    "    basin_df_con['lat'] = basin_df_con['lat'].map(float)\n",
    "    #set index\n",
    "    basin_df_con.set_index('basin',inplace=True)\n",
    "    \n",
    "    return basin_df_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_dfs = gen_field_df(split_basin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basin_tuple(basin_dfs):\n",
    "    '''convert basin row data to list of tuple\n",
    "    '''\n",
    "    basins_dict = {}\n",
    "    basins = basin_dfs.index.unique()\n",
    "    for basin in basins:\n",
    "         \n",
    "        basin_ready_tuple = basin_dfs[basin_dfs.index == basin] ##basin index equal to one of element\n",
    "        basin_tuples = [tuple(x) for x in basin_ready_tuple.values] ## convert data frame to tuple\n",
    "        basins_dict[basin] = basin_tuples\n",
    "        \n",
    "    return basins_dict\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_tuple = get_basin_tuple(basin_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inside_poly(field_coor,basin_tuple,basin):\n",
    "    '''field coordinate and one basin_tuple\n",
    "    Args:\n",
    "        field coordinate,(1,2),tuple\n",
    "        basin tuple,[(1,2),(3,4).......],list\n",
    "        basin, basin name,string\n",
    "    Return:\n",
    "        inside or not and basin name,(True,'Basin_name')\n",
    "    '''\n",
    "    inside_rect = False #inside flag\n",
    "    crossing_point = 0\n",
    "    max_long = max([x[0] for x in basin_tuple]) #max long\n",
    "    min_long = min([x[0] for x in basin_tuple]) #min long\n",
    "    max_lat = max([x[1] for x in basin_tuple]) #max lat\n",
    "    min_lat = min([x[1] for x in basin_tuple]) #min lat\n",
    "    if (min_long<=field_coor[0] and max_long>=field_coor[1] \n",
    "        or min_lat<field_coor[1] and max_lat>field_coor[1]): # point inside the rectangele\n",
    "        for i in range(len(basin_tuple)): #iterate the poly points\n",
    "            slope = (basin_tuple[i+1][1] - basin_tuple[i][1])/ (basin_tuple[i+1][0] - basin_tuple[i][0])\n",
    "            if (field_coor[0] - basin_tuple[i][1])/(field_coor[1]-basin[i][0]) <= slope:\n",
    "                crossing_point += 1\n",
    "        if crossing_point%2 == 0:\n",
    "            inside_rect = True\n",
    "            \n",
    "    return inside_rect,basin\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determin_range(field_file,basin_tuple):\n",
    "    '''project field lat and long to correspoding basin name\n",
    "    \n",
    "    Args:\n",
    "        field,dataframe with storing field coordinates\n",
    "        basin,basin coordinates\n",
    "    Returns:\n",
    "        field-basin, corresponding dataframe\n",
    "        \n",
    "    '''\n",
    "    ## read in field data\n",
    "    field = pd.read_excel(field_file)\n",
    "#     basin = pd.read_excel('basin.xlsx')\n",
    "#     field_basin = {}\n",
    "    field_arr = field[['field','long','lat']]\n",
    "    field_arr.set_index('field',inplace=True)\n",
    "    field_arr['basin'] = None\n",
    "    for i in range(len(field_arr)):\n",
    "        field_row = field_arr.iloc[i] ## get field coord\n",
    "        field_coor = tuple(field_row.to_list()) ## get field coordinate tuple\n",
    "        ## for each point searching inside basins\n",
    "        for key in basin_tuple.keys(): ## for one basin\n",
    "            ##check for each basin coorinates\n",
    "            is_inside,basin = check_field_basin(field_coor,basin_tuple[key],key) ##match field to basin\n",
    "            if is_inside: ## if point inside this basin\n",
    "                field_arr['basin'] = basin_name ## save basin name to field row\n",
    "    return field_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins_range = get_lat_long_range(split_basin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "field_basin = get_basin('field.xlsx',basins_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_basin.to_excel('field_basin.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    lng = None\n",
    "    lat = None\n",
    " \n",
    "    def __init__(self, lng, lat):\n",
    "        self.lng = lng\n",
    "        self.lat = lat\n",
    "        \n",
    "def get_polygon_bounds(points):\n",
    "    length = len(points)\n",
    "    top = down = left = right = points[0]\n",
    "    for i in range(1, length):\n",
    "        if points[i].lng > top.lng:\n",
    "            top = points[i]\n",
    "        elif points[i].lng < down.lng:\n",
    "            down = points[i]\n",
    "        else:\n",
    "            pass\n",
    "        if points[i].lat > right.lat:\n",
    "            right = points[i]\n",
    "        elif points[i].lat < left.lat:\n",
    "            left = points[i]\n",
    "        else:\n",
    "            pass\n",
    "    top_left = Point(top.lng, left.lat)\n",
    "    top_right = Point(top.lng, right.lat)\n",
    "    down_right = Point(down.lng, right.lat)\n",
    "    down_left = Point(down.lng, left.lat)\n",
    "    return [top_left, top_right, down_right, down_left]\n",
    "\n",
    "def is_point_in_rect(point, polygon_bounds):\n",
    "    top_left = polygon_bounds[0]\n",
    "    top_right = polygon_bounds[1]\n",
    "    down_right = polygon_bounds[2]\n",
    "    down_left = polygon_bounds[3]\n",
    "    return (down_left.lng <= point.lng <= top_right.lng\n",
    "            and top_left.lat <= point.lat <= down_right.lat)\n",
    "\n",
    "def is_point_in_polygon(point, points):\n",
    "    polygon_bounds = get_polygon_bounds(points)\n",
    "    if not is_point_in_rect(point, polygon_bounds):\n",
    "        return False\n",
    "    length = len(points)\n",
    "    point_start = points[0]\n",
    "    flag = False\n",
    "    for i in range(1, length):\n",
    "        point_end = points[i]\n",
    "        # 点与多边形顶点重合\n",
    "        if (point.lng == point_start.lng and point.lat == point_start.lat) or (\n",
    "                point.lng == point_end.lng and point.lat == point_end.lat):\n",
    "            return True\n",
    "        # 判断线段两端点是否在射线两侧\n",
    "        if (point_end.lat < point.lat <= point_start.lat) or (\n",
    "                point_end.lat >= point.lat > point_start.lat):\n",
    "            # 线段上与射线 Y 坐标相同的点的 X 坐标\n",
    "            if point_end.lat == point_start.lat:\n",
    "                x = (point_start.lng + point_end.lng) / 2\n",
    "            else:\n",
    "                x = point_end.lng - (point_end.lat - point.lat) * (\n",
    "                        point_end.lng - point_start.lng) / (\n",
    "                        point_end.lat - point_start.lat)\n",
    "            # 点在多边形的边上\n",
    "            if x == point.lng:\n",
    "                return True\n",
    "            # 射线穿过多边形的边界\n",
    "            if x > point.lng:\n",
    "                flag = not flag\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    " \n",
    "        point_start = point_end\n",
    "    return flag\n",
    "\n",
    "def test(input_lng=116.732617, input_lat=39.722676):\n",
    "    # polyline 是多个坐标点，形如\n",
    "    # ['116.732617,39.722676', '116.732617,39.722676', '116.732617,39.722676',\n",
    "    # '116.732617,39.722676', '116.732617,39.722676']\n",
    "    polyline = []\n",
    " \n",
    "    points = []\n",
    "    for line in polyline:\n",
    "        if line:\n",
    "            try:\n",
    "                lng, lat = line.split(',')\n",
    "                points.append(Point(float(lng), float(lat)))\n",
    "            except ValueError:\n",
    "                pass\n",
    "    if points:\n",
    "        is_point_in_polygon(Point(float(input_lng), float(input_lat)), points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
