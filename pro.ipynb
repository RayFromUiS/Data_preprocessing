{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import xlrd\n",
    "import fileinput\n",
    "import sys\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "import re\n",
    "import random\n",
    "from random import sample ## random choose samples\n",
    "from math import floor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CSV files\n",
    "def read_in_files(year_pair):\n",
    "    \n",
    "    '''read in files and return the array of dataframe\n",
    "    '''\n",
    "    data_folder = 'Data/'\n",
    "#     extention = '.xls'\n",
    "    common_name = 'production'\n",
    "    csv_ext = '.csv'\n",
    "    year_dfs = {}\n",
    "    dfs =[]  \n",
    "    mix_year,max_year = year_pair ## get min,max year \n",
    "    for year in range(mix_year,max_year):\n",
    "        file_name = str(year) + common_name + csv_ext\n",
    "        file = os.path.join(data_folder,file_name)  \n",
    "        df = pd.read_csv(file)\n",
    "        df.columns = df.columns.to_series().apply(lambda x: x.strip()) ##strip the column names\n",
    "        dfs.append(df)\n",
    "    year_df = pd.concat(dfs,sort = False)\n",
    "    #     print(f'first df has the column length of {result.columns}{len(result.columns)}')\n",
    "\n",
    "    return year_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wells01_df = read_in_files((2015,2016))  ## 1985,2012 has the same column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_iterator(it):\n",
    "    for x in it:\n",
    "        print(x, end=' ')\n",
    "    print('')  # for new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check which row has strange letter\n",
    "# for i in range(1,len(col)+1):\n",
    "# #     print(i)\n",
    "    \n",
    "#     new_col = map(float,col[i-1:i])\n",
    "# #     print(new_col,i)\n",
    "#     print_iterator(new_col)\n",
    "#     print(i) ##53179 column has a empty letter,somehow strip is not worked\n",
    "#     except ValueError:\n",
    "#         print(f'{i} row data has been corputed')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_data(df,pair_year):\n",
    "    '''\n",
    "    get monthly data for oil and gas production\n",
    "    '''\n",
    "    oil= 'OIL'\n",
    "    gas = 'GAS'\n",
    "    lng = 'LNG'\n",
    "    ngl = 'NGL'\n",
    "    condensate ='CONDENSATE'\n",
    "    water = 'WATER'\n",
    "    middle='PRODUCTION'\n",
    "    month_pair = {\n",
    "    'JANUARY':1,\n",
    "    'FEBRUARY':2,\n",
    "    'MARCH':3,\n",
    "    'APRIL':4,\n",
    "    'MAY':5,\n",
    "    'JUNE':6,\n",
    "    'JULY':7,\n",
    "    'AUGUST':8,\n",
    "    'SEPTEMBER':9,\n",
    "    'OCTOBER':10,\n",
    "    'NOVEMBER':11,\n",
    "    'DECEMBER':12\n",
    "    }\n",
    "    \n",
    "    ##container for saving months data\n",
    "    gas_oil_month_dfs = []\n",
    "    for month in month_pair.keys():## iterate all ove the months\n",
    "        if pair_year==(1985,2012):\n",
    "            ##slicing the dataframe\n",
    "            gas_oil_month = df[['API','YEAR',gas+'_'+middle+'_'+month,oil+'_'+middle+'_'+month]]\n",
    "            ## add month as a column\n",
    "            gas_oil_month['Month'] = df['YEAR'].astype('str') +'/' +  str(month_pair[month])\n",
    "            ## rename the columns for preparing the concatation\n",
    "            gas_oil_month.columns = ['Well ID','Year','Month gas (mmscf)','Month oil (bbl)','Month (yyyymm)']\n",
    "        elif pair_year==(2012,2013):\n",
    "            gas_oil_month = df[['WELL_API','PRODUCTION_YEAR',gas+'_'+middle+'_'+month,oil+'_'+middle+'_'+month]]\n",
    "            gas_oil_month['Month'] = df['PRODUCTION_YEAR'].astype('str') +'/'+ str(month_pair[month])\n",
    "            gas_oil_month.columns = ['Well ID','Year','Month gas (mmscf)','Month oil (bbl)','Month (yyyymm)']\n",
    "        elif pair_year==(2013,2015): ## has lng production\n",
    "            gas_oil_month = df[['API','YEAR',gas+'_'+middle+'_'+month,\n",
    "                                            oil+'_'+middle+'_'+month, lng+'_'+middle[0:4]+'_'+month[0:3]]]\n",
    "            gas_oil_month['Month'] = df['YEAR'].astype('str') +'/' +  str(month_pair[month])\n",
    "            gas_oil_month.columns = ['Well ID','Year','Month gas (mmscf)','Month oil (bbl)','Month condensate (bbl)','Month (yyyymm)']       \n",
    "        elif pair_year==(2015,2016): ## has horizontial indicator\n",
    "           \n",
    "            gas_oil_month = df[['API','YEAR','Horizontal Well Indicator',gas+'_'+middle+'_'+month,\n",
    "                                            oil+'_'+middle+'_'+month, ngl+'_'+middle[0:4]+'_'+month[0:3]]]\n",
    "            gas_oil_month['Month'] = df['YEAR'].astype('str') +'/' +  str(month_pair[month])\n",
    "            gas_oil_month.columns = ['Well ID','Year','Well_type','Month gas (mmscf)','Month oil (bbl)',\n",
    "                                     'Month condensate (bbl)','Month (yyyymm)']    \n",
    "        elif pair_year==(2016,2018):## add water column and condensate conlumns\n",
    "            gas_oil_month = df[['API','Year','Horizontal Well Indicator',gas.title()+'_'+month.title(),\n",
    "                                oil.title()+'_'+month.title(),water.title()+'_'+month.title(), \n",
    "                                condensate.title()+'_'+month.title()]]\n",
    "            gas_oil_month['Month'] = df['Year'].astype('int').astype('str')+ '/'+  str(month_pair[month])\n",
    "            gas_oil_month.columns = ['Well ID','Year','Well_type','Month gas (mmscf)','Month oil (bbl)',\n",
    "                                     'Month condensate (bbl)','Month water (bbl)','Month (yyyymm)'] \n",
    "            \n",
    "        elif pair_year==(2018,2019):\n",
    "            \n",
    "            gas_oil_month = df[['API','Year','Well_type',month[0:3].title()+'_'+gas.title(),\n",
    "                                month[0:3].title()+'_'+oil.title(),month[0:3].title()+'_'+water.title(), \n",
    "                                month[0:3].title()+'_'+ngl]]\n",
    "            gas_oil_month['Month'] = df['Year'].astype('int').astype('str')+ '/'+ str(month_pair[month]) \n",
    "            gas_oil_month.columns = ['Well ID','Year','Well_type','Month gas (mmscf)','Month oil (bbl)',\n",
    "                                     'Month condensate (bbl)','Month water (bbl)','Month (yyyymm)'] \n",
    "        else:\n",
    "            print(f'{year_pair} is out of range')\n",
    "\n",
    "        gas_oil_month_dfs.append(gas_oil_month)\n",
    "    \n",
    "    result = pd.concat(gas_oil_month_dfs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "preprocessed_wells_group = get_monthly_data(wells05_df,(2018,2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_to_standard(preprocessed_wells_group,pair_year):\n",
    "    '''change the column names and covert the unit\n",
    "        as well as add columns with none value if lack of\n",
    "    '''\n",
    "    standard_cols= ['Well ID','Well name','Month (yyyymm)','Monthly days','Month oil (bbl)','Month water (bbl)',\\\n",
    "                    'Month gas (mmscf)','Month condensate (bbl)','Month water injection (bbl)','Month gas injection (mmscf)',\\\n",
    "                    'Month steam injection (bbl)','Pool','Field']\n",
    "    \n",
    "    standard_df = pd.DataFrame()\n",
    "    standard_df = preprocessed_wells_group \n",
    "    if pair_year==(1985,2012):\n",
    "        selected_cols = ['Month (yyyymm)','Well ID','Month oil (bbl)','Month gas (mmscf)']\n",
    "    elif pair_year==(2012,2013):\n",
    "        selected_cols = ['Well ID','Year','Month gas (mmscf)','Month oil (bbl)','Month (yyyymm)']\n",
    "    elif pair_year==(2013,2015): \n",
    "        selected_cols = ['Well ID','Year','Month gas (mmscf)','Month oil (bbl)','Month condensate (bbl)','Month (yyyymm)']\n",
    "    elif pair_year==(2015,2016):\n",
    "        selected_cols = ['Well ID','Year','Well_type','Month gas (mmscf)','Month oil (bbl)',\n",
    "                                     'Month condensate (bbl)','Month (yyyymm)']  \n",
    "    elif pair_year==(2016,2018):\n",
    "        selected_cols =['Well ID','Year','Well_type','Month gas (mmscf)','Month oil (bbl)',\n",
    "                                     'Month condensate (bbl)','Month (yyyymm)']  \n",
    "    elif pair_year==(2018,2019):\n",
    "        selected_cols =['Well ID','Year','Well_type','Month gas (mmscf)','Month oil (bbl)',\n",
    "                                     'Month condensate (bbl)','Month (yyyymm)']  \n",
    "    standard_df = standard_df[selected_cols]\n",
    "    \n",
    "    ## add column nonexisted comparing to standard_cols\n",
    "    for col in standard_cols:\n",
    "        if col not in  standard_df.columns:\n",
    "              standard_df[col] = None\n",
    "    ## unit convert for gas mcf\n",
    "#     if standard_df['Month gas (mmscf)'].dtype != 'object':\n",
    "    standard_df['Month gas (mmscf)'] = standard_df['Month gas (mmscf)'].astype('str').\\\n",
    "                                        apply(lambda x:x.strip().replace(',','')).map(float)\n",
    "    standard_df['Month gas (mmscf)'] = standard_df['Month gas (mmscf)'].div(1000).round(6)\n",
    "  \n",
    "        \n",
    "    ## slcing the df\n",
    "    result = standard_df[standard_cols]\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "proprcessed_dfs =[]\n",
    "def main():\n",
    "    \n",
    "#     proprcessed_dfs = []\n",
    "    ## year_pairs to group dataframe together,since different years have dif column names\n",
    "    year_pairs = [(1985,2012),(2012,2013),(2013,2015),(2015,2016),(2016,2018),(2018,2019)]\n",
    "    ## read in files and saved as dataframes\n",
    "    for year_pair in year_pairs:\n",
    "        year_df= read_in_files(year_pair)\n",
    "        preprocessed_wells_group = get_monthly_data(year_df,year_pair)\n",
    "        modified_df =  modify_to_standard(preprocessed_wells_group,year_pair)\n",
    "        proprcessed_dfs.append(modified_df)\n",
    "        print(f'{year_pair} data has been preprocessed')\n",
    "#         message = save_preprocessed_df_to(preprocessed_wells_group)##\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1985, 2012) data has been preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2012, 2013) data has been preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2013, 2015) data has been preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2015, 2016) data has been preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 2018) data has been preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2018, 2019) data has been preprocessed\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "proprcessed_dfs[0].to_csv('well1982-2012.csv') ## save file for  get well names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proprcessed_dfs[1].to_csv('well2012-2014.csv') ##backpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_wells(fielname):\n",
    "    '''\n",
    "    handle with degree with 0,values,and convert to decimical degrees\n",
    "    generate the standard column names\n",
    "    '''\n",
    "    \n",
    "    data_foler = 'Data/'\n",
    "    standar_cols = ['Country','State','Basin','Field','Latitude','Longitude','Well ID','Well name']\n",
    "    ##read in data\n",
    "    file = os.path.join(data_foler,fielname)\n",
    "    df = pd.read_excel(file)\n",
    "    ## drop first col\n",
    "    df.drop(['Unnamed: 0'],axis = 1,inplace =True)\n",
    "    ## lat an long with 0\n",
    "    mask_lat = (df['WELL_HEAD_LATITUDE_DEGREES'] <= 1)## lat has positive value\n",
    "    mask_long = (df['WELL_HEAD_LONGITUDE_DEGREES'] >=1) ##long has negative value\n",
    "#     ##set those column with none value\n",
    "#     df[mask_lat]['WELL_HEAD_LATITUDE_DEGREES'] =None\n",
    "#     df[mask_lat]['WELL_HEAD_LATITUDE_MINUTES'] =None   \n",
    "#     df[mask_lat]['WELL_HEAD_LATITUDE_SECONDS'] =None\n",
    "#     df[mask_long]['WELL_HEAD_LONGITUDE_DEGREES'] =None\n",
    "#     df[mask_long]['WELL_HEAD_LONGITUDE_MINUTES']  =None\n",
    "#     df[mask_long]['WELL_HEAD_LONGITUDE_SECONDS'] = None\n",
    "    ## get the masked left with long and lat none,and bigger > standard\n",
    "    df_left = df[~(mask_lat | mask_long)]\n",
    "#     print(df_left.head())\n",
    "#     print(len(df_left))\n",
    "    df_left['lat'] = df_left['WELL_HEAD_LATITUDE_DEGREES'] + df_left['WELL_HEAD_LATITUDE_MINUTES'].divide(60).round(6)\\\n",
    "                    + df_left['WELL_HEAD_LATITUDE_SECONDS'].divide(3600).round(6)\n",
    "    df_left['long'] = df_left['WELL_HEAD_LONGITUDE_DEGREES']  - df_left['WELL_HEAD_LONGITUDE_MINUTES'].divide(60).round(6)\\\n",
    "                -  df_left['WELL_HEAD_LONGITUDE_SECONDS'].divide(3600).round(6)\n",
    "    ##select the colmns\n",
    "    selected = ['PERMIT_ID','lat','long']\n",
    "    ## add states \n",
    "    result = df_left[selected]\n",
    "    result['Country'] = 'UNITED STATES OF AMERICAN'\n",
    "    result['State'] = 'WEST VIRGINIA'\n",
    "    result['Well name'] = None\n",
    "    result['Field'] = None\n",
    "    result['Basin'] = None\n",
    "    ## change column names in all\n",
    "    result.columns = ['Well ID','Latitude','Longitude','Country','State','Well name','Field','Basin']\n",
    "    result = result[standar_cols]\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\zhangchunlei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "well_sta = static_wells('WellLocation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  sample_wells(static,dynamics):\n",
    "    '''\n",
    "    chosen a number of wells and according to that wells\n",
    "    generate well dynamics well dataframe and \n",
    "    static dataframe\n",
    "    ------------------------------------------\n",
    "    input:\n",
    "    two dataframe\n",
    "    output:\n",
    "    well name and two selected dataframe\n",
    "    ------------------------------------------\n",
    "    '''\n",
    "    portion = 0.15  ## portion of total wells been choosen\n",
    "    random.seed = 32\n",
    "    ## get dynmaics wells\n",
    "    wells = list(dynamics['Well ID'].unique())\n",
    "    ## choose number of wells\n",
    "    chosen_number = floor(len(wells)*portion)  ## chose 1/5 of origianl well numbers\n",
    "    chosen_wells = sample(wells, chosen_number)\n",
    "    ##get dynamics dataframe\n",
    "    chosen_dynamics = dynamics[dynamics['Well ID'].isin(chosen_wells)]\n",
    "    ##get statics daframe\n",
    "    chosen_statics = static[static['Well ID'].isin(chosen_wells)]\n",
    "    \n",
    "    \n",
    "    return chosen_wells,chosen_dynamics,chosen_statics\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_wells,chosen_dynamics,chosen_statics = sample_wells(well_sta,wells_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamics(chosen_wells,proprcessed_dfs):\n",
    "    '''\n",
    "    retrieve dynamics well data from preprocessed df\n",
    "    -----------------------------------------------\n",
    "    input: well names and original df list:lists\n",
    "    out:df in the name of chosen_wells:dataframe\n",
    "    --------------------------------------------\n",
    "    '''\n",
    "    length = len(proprcessed_dfs)\n",
    "    ID_col_name = 'Well ID'\n",
    "    years_dfs = []\n",
    "    for i in range(1,length):\n",
    "        mask = proprcessed_dfs[i][ID_col_name].isin(chosen_wells)\n",
    "        years_df = proprcessed_dfs[i][mask]\n",
    "        years_dfs.append(years_df)\n",
    "    return years_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_wells = get_dynamics(chosen_wells,proprcessed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_together(chosen_dynamics,dyn_wells):\n",
    "    '''\n",
    "    merge dynamics dataframe together for all year pairs\n",
    "    --------------------------------------------------\n",
    "    input:two data sets of dataframe from years\n",
    "          dtype:dataframe\n",
    "    outpu:one merged datafraem\n",
    "          dtype:dafarame\n",
    "    ---------------------------------------------------\n",
    "    '''\n",
    "    concat_years = pd.concat(dyn_wells) ##concat well list first\n",
    "    return pd.concat([chosen_dynamics,concat_years],sort =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics_wells_com =  merge_df_together(chosen_dynamics,dyn_wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_for_time(date):\n",
    "    '''\n",
    "    output string format time\n",
    "    '''\n",
    "    new_date = datetime.strptime(date,'%Y/%m')\n",
    "    str_time = new_date.strftime('%Y/%m')\n",
    "    return str_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dyna(dynamics_wells_com):\n",
    "    '''\n",
    "    format month,ID columns\n",
    "    --------------------------------------------------\n",
    "    input:dataframe\n",
    "    outpu::dafarame\n",
    "    ---------------------------------------------------\n",
    "    '''\n",
    "    dynamics_wells_com['Month (yyyymm)'] = dynamics_wells_com['Month (yyyymm)'].apply(str_for_time)\n",
    "    dynamics_wells_com.sort_values(by =['Well ID','Month (yyyymm)'],inplace =True)\n",
    "    dynamics_wells_com['Well ID'] = dynamics_wells_com['Well ID'].astype('int')\n",
    "    \n",
    "    return dynamics_wells_com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statics_and_dynamics():\n",
    "    ## choose from 1985-2012 well production data, get the wells location\n",
    "    wells_df = pd.read_csv('well1982-2012.csv')\n",
    "    # proprcessed_dfs[0].to_csv('well1982-2012.csv')\n",
    "    chosen_wells,chosen_dynamics,chosen_statics = sample_wells(well_sta,wells_df)\n",
    "    ## according to the chosen wells select residual dynamics data\n",
    "    dyn_wells = get_dynamics(chosen_wells,proprcessed_dfs)\n",
    "    ##merg all dynamics data together\n",
    "    dynamics_wells_com =  merge_df_together(chosen_dynamics,dyn_wells)\n",
    "    ##format the dynamics_wells_com\n",
    "    dynamics_wells_com_format = format_dyna(dynamics_wells_com)\n",
    "    return chosen_wells,dynamics_wells_com_format,chosen_statics\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_wells,dynamics_wells_com,chosen_statics = get_statics_and_dynamics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_wells_to_file(chosen_wells):\n",
    "    '''\n",
    "    write choose well name to file\n",
    "    '''\n",
    "    with open('well_names_chosen.csv','w+') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow(chosen_wells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics_wells_com.to_csv('chosen_well_dynamics.csv') ## save reslut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_statics.to_csv('chosen_well_static.csv') ## save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
